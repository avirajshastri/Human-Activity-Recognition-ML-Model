{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1K1scMT6M3eKCzc42y4nZIuI71yWMDHhv","authorship_tag":"ABX9TyPlYo0WZ2vsiwS3wl3zJmXw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XIMuhjC0WYuW","executionInfo":{"status":"ok","timestamp":1695740824819,"user_tz":-330,"elapsed":5766,"user":{"displayName":"Arun Jain","userId":"13434028188806662167"}},"outputId":"418dfbfd-b797-4e58-ea39-96777399255f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n"]}]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"id":"Qfe-UIZuWmPt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from numpy import mean\n","from numpy import std\n","from numpy import dstack\n","from pandas import read_csv\n","from matplotlib import pyplot\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","from keras.utils import to_categorical\n","import seaborn as sns\n","import numpy as np\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n","from sklearn import metrics\n","from sklearn.metrics import classification_report\n","from matplotlib import pyplot as plt\n","import pandas as pd\n"],"metadata":{"id":"LPZ6iskHWu_1","executionInfo":{"status":"error","timestamp":1695744575176,"user_tz":-330,"elapsed":3888,"user":{"displayName":"Arun Jain","userId":"13434028188806662167"}},"colab":{"base_uri":"https://localhost:8080/","height":383},"outputId":"d397f831-91d5-4308-9455-a84920a2d9ac"},"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ba8d26bb22c1>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.layers.convolutional'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["def load_file(filepath):\n"," dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n"," return dataframe.values"],"metadata":{"id":"CpKuzk2MWC6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_group(filenames, prefix=''):\n"," loaded = list()\n"," for name in filenames:\n","    data = load_file(prefix + name)\n","\n","    loaded.append(data)\n"," # stack group so that features are the 3rd dimension\n"," loaded = dstack(loaded)\n"," return loaded"],"metadata":{"id":"SGVkIJt0edkd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_dataset_group(group, prefix=''):\n"," filepath = prefix + group + '/Inertial Signals/'\n"," print('File Path : ',filepath)\n"," # load all 9 files as a single array\n"," filenames = list()\n"," # total acceleration\n"," filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n"," # body acceleration\n"," filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n"," # body gyroscope\n"," filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n"," # load input data\n"," X = load_group(filenames, filepath)\n"," # load class output\n"," y = load_file(prefix + group + '/y_'+group+'.txt')\n"," return X, y"],"metadata":{"id":"dRATBGKaeAu9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load dataset\n","from numpy import dstack\n","from pandas import read_csv\n","\n","# load a single file as a numpy array\n","def load_file(filepath):\n"," dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n"," return dataframe.values\n","\n","# load a list of files, such as x, y, z data for a given variable\n","def load_group(filenames, prefix=''):\n"," loaded = list()\n"," for name in filenames:\n","    data = load_file(prefix + name)\n","    loaded.append(data)\n"," # stack group so that features are the 3rd dimension\n"," loaded = dstack(loaded)\n"," return loaded\n","\n","# load a dataset group, such as train or test\n","def load_dataset(group, prefix=''):\n"," filepath = prefix + group + '/Inertial Signals/'\n"," # load all 9 files as a single array\n"," filenames = list()\n"," # total acceleration\n"," filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n"," # body acceleration\n"," filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n"," # body gyroscope\n"," filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n"," # load input data\n"," X = load_group(filenames, filepath)\n"," # load class output\n"," y = load_file(prefix + group + '/y_'+group+'.txt')\n"," return X, y\n","\n","# load all train\n","trainX, trainy = load_dataset('train', '/content/drive/MyDrive/UCI HAR Dataset/')\n","print(trainX.shape, trainy.shape)\n","# load all test\n","testX, testy = load_dataset('test', '/content/drive/MyDrive/UCI HAR Dataset/')\n","print(testX.shape, testy.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qcCQp9dPkBvi","executionInfo":{"status":"ok","timestamp":1671691482393,"user_tz":-330,"elapsed":13718,"user":{"displayName":"Arun Jain","userId":"13434028188806662167"}},"outputId":"a12b223e-5f86-4645-98b3-b7e8fff69c43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(7352, 128, 9) (7352, 1)\n","(2947, 128, 9) (2947, 1)\n"]}]},{"cell_type":"code","source":["# summarize the balance of classes in an output variable column\n","def class_breakdown(data):\n"," # convert the numpy array into a dataframe\n"," df = DataFrame(data)\n"," # group data by the class value and calculate the number of rows\n"," counts = df.groupby(0).size()\n"," # retrieve raw rows\n"," counts = counts.values\n"," # summarize\n"," for i in range(len(counts)):\n","     percent = counts[i] / len(df) * 100\n","     print('Class=%d, total=%d, percentage=%.3f' % (i+1, counts[i], percent))"],"metadata":{"id":"fiAJEWuSlFkZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# summarize class balance\n","from numpy import array\n","from numpy import vstack\n","from pandas import read_csv\n","from pandas import DataFrame\n","\n","# load a single file as a numpy array\n","def load_file(filepath):\n","    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n","    return dataframe.values\n","\n","# summarize the balance of classes in an output variable column\n","def class_breakdown(data):\n"," # convert the numpy array into a dataframe\n"," df = DataFrame(data)\n"," # group data by the class value and calculate the number of rows\n"," counts = df.groupby(0).size()\n"," # retrieve raw rows\n"," counts = counts.values\n"," # summarize\n"," for i in range(len(counts)):\n","      percent = counts[i] / len(df) * 100\n","      print('Class=%d, total=%d, percentage=%.3f' % (i+1, counts[i], percent))\n","\n","# load train file\n","trainy = load_file('/content/drive/MyDrive/UCI HAR Dataset/train/y_train.txt')\n","# summarize class breakdown\n","print('Train Dataset')\n","class_breakdown(trainy)\n","\n","# load test file\n","testy = load_file('/content/drive/MyDrive/UCI HAR Dataset/test/y_test.txt')\n","# summarize class breakdown\n","print('Test Dataset')\n","class_breakdown(testy)\n","\n","# summarize combined class breakdown\n","print('Both')\n","combined = vstack((trainy, testy))\n","class_breakdown(combined)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G0je6kxklUj2","executionInfo":{"status":"ok","timestamp":1671691940339,"user_tz":-330,"elapsed":521,"user":{"displayName":"Arun Jain","userId":"13434028188806662167"}},"outputId":"31ef5e10-e771-4983-cbdb-5aa06e43a551"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Dataset\n","Class=1, total=1226, percentage=16.676\n","Class=2, total=1073, percentage=14.595\n","Class=3, total=986, percentage=13.411\n","Class=4, total=1286, percentage=17.492\n","Class=5, total=1374, percentage=18.689\n","Class=6, total=1407, percentage=19.138\n","Test Dataset\n","Class=1, total=496, percentage=16.831\n","Class=2, total=471, percentage=15.982\n","Class=3, total=420, percentage=14.252\n","Class=4, total=491, percentage=16.661\n","Class=5, total=532, percentage=18.052\n","Class=6, total=537, percentage=18.222\n","Both\n","Class=1, total=1722, percentage=16.720\n","Class=2, total=1544, percentage=14.992\n","Class=3, total=1406, percentage=13.652\n","Class=4, total=1777, percentage=17.254\n","Class=5, total=1906, percentage=18.507\n","Class=6, total=1944, percentage=18.876\n"]}]},{"cell_type":"code","source":["# load data\n","trainX, trainy = load_dataset('train', '/content/drive/MyDrive/UCI HAR Dataset/')"],"metadata":{"id":"MEFuItZEmvos"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sub_map = load_file('/content/drive/MyDrive/UCI HAR Dataset/train/subject_train.txt')\n","train_subjects = np.unique(sub_map)\n","print(train_subjects)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5VEG2GBncdU","executionInfo":{"status":"ok","timestamp":1671692320489,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arun Jain","userId":"13434028188806662167"}},"outputId":"86d9775f-7647-4dac-dfb2-8e33bf8cf39b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 1  3  5  6  7  8 11 14 15 16 17 19 21 22 23 25 26 27 28 29 30]\n"]}]},{"cell_type":"code","source":["# get all data for one subject\n","def data_for_subject(X, y, sub_map, sub_id):\n"," # get row indexes for the subject id\n"," ix = [i for i in range(len(sub_map)) if sub_map[i]==sub_id]\n"," # return the selected samples\n"," return X[ix, :, :], y[ix]"],"metadata":{"id":"tkEPMR-fn_jS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert a series of windows to a 1D list\n","def to_series(windows):\n"," series = list()\n"," for window in windows:\n"," # remove the overlap from the window\n","  half = int(len(window) / 2) - 1\n"," for value in window[-half:]:\n","  series.append(value)\n"," return series"],"metadata":{"id":"CGFnQW_ao5sg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot the data for one subject\n","def plot_subject(X, y):\n"," plt.figure()\n"," # determine the total number of plots\n"," n, off = X.shape[2] + 1, 0\n"," # plot total acc\n"," for i in range(3):\n","  plt.subplot(n, 1, off+1)\n"," plt.plot(to_series(X[:, :, off]))\n"," plt.title('total acc '+str(i), y=0, loc='left')\n"," off += 1\n"," # plot body acc\n"," for i in range(3):\n","  plt.subplot(n, 1, off+1)\n"," plt.plot(to_series(X[:, :, off]))\n"," plt.title('body acc '+str(i), y=0, loc='left')\n"," off += 1\n"," # plot body gyro\n"," for i in range(3):\n","  plt.subplot(n, 1, off+1)\n"," plt.plot(to_series(X[:, :, off]))\n"," plt.title('body gyro '+str(i), y=0, loc='left')\n"," off += 1\n"," # plot activities\n"," plt.subplot(n, 1, n)\n"," plt.plot(y)\n"," plt.title('activity', y=0, loc='left')\n"," plt.show()"],"metadata":{"id":"736D_CWEpD16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load all train\n","X_train, Y_train = load_dataset_group('train', '/content/drive/MyDrive/UCI HAR Dataset/')\n","# load all test\n","X_test, Y_test = load_dataset_group('test', '/content/drive/MyDrive/UCI HAR Dataset/')\n","# zero-offset class values\n","Y_train = Y_train - 1\n","Y_test = Y_test - 1\n","# one hot encode y\n","Y_train = to_categorical(Y_train)\n","Y_test = to_categorical(Y_test)\n","print('X_train.shape : ', X_train.shape)\n","print('Y_train.shape : ', Y_train.shape)\n","print('X_test.shape : ', X_test.shape)\n","print('Y_test.shape : ', Y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rx2Guuwr1Ed","executionInfo":{"status":"ok","timestamp":1671693493420,"user_tz":-330,"elapsed":5227,"user":{"displayName":"Arun Jain","userId":"13434028188806662167"}},"outputId":"c34c8959-b1e5-41bb-ea59-5570798ae6a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File Path :  /content/drive/MyDrive/UCI HAR Dataset/train/Inertial Signals/\n","File Path :  /content/drive/MyDrive/UCI HAR Dataset/test/Inertial Signals/\n","X_train.shape :  (7352, 128, 1)\n","Y_train.shape :  (7352, 6)\n","X_test.shape :  (2947, 128, 1)\n","Y_test.shape :  (2947, 6)\n"]}]},{"cell_type":"code","source":["verbose = 1\n","epochs = 50\n","batch_size = 20\n","n_timesteps = X_train.shape[1]\n","n_features = X_train.shape[2]\n","n_outputs = Y_train.shape[1]"],"metadata":{"id":"--N1Iwl8srDG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint = ModelCheckpoint(\"har_weights.h5\", monitor='val_acc', verbose=1 , save_best_only=True, save_weights_only=False, mode='auto')"],"metadata":{"id":"CMslRqxNswlP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# fit and evaluate a model\n","def evaluate_model(trainX, trainy, testX, testy):\n"," verbose, epochs, batch_size = 0, 10, 32\n"," n_timesteps, n_features = trainX.shape[1], trainX.shape[2]\n"," model = Sequential()\n"," model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n"," model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n"," model.add(Dropout(0.5))\n"," model.add(MaxPooling1D(pool_size=2))\n"," model.add(Flatten())\n"," model.add(Dense(100, activation='relu'))\n"," model.add(Dense(n_outputs, activation='softmax'))\n"," model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"," # fit network\n"," model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n"," # evaluate model\n"," _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n"," return accuracy"],"metadata":{"id":"PoZmLcVZvSha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# summarize scores\n","def summarize_results(scores):\n"," print(scores)\n"," m, s = mean(scores), std(scores)\n"," print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"],"metadata":{"id":"yoKwzLsOvhiW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run an experiment\n","def run_experiment(repeats=10):\n"," # load data\n"," trainX, trainy, testX, testy = pd.read_csv(\"/content/drive/MyDrive/UCI HAR Dataset/train/X_train.txt\"),pd.read_csv(\"/content/drive/MyDrive/UCI HAR Dataset/train/y_train.txt\"),pd.read_csv(\"/content/drive/MyDrive/UCI HAR Dataset/test/X_test.txt\"),pd.read_csv(\"/content/drive/MyDrive/UCI HAR Dataset/test/y_test.txt\")\n"," # repeat experiment\n"," scores = list()\n"," for r in range(repeats):\n","  score = evaluate_model(trainX, trainy, testX, testy)\n"," score = score * 100.0\n"," print('>#%d: %.3f' % (r+1, score))\n"," scores.append(score)\n"," # summarize results\n"," summarize_results(scores)"],"metadata":{"id":"07vhmhaDvk5P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["run_experiment()"],"metadata":{"id":"4Kkpw0atvx0H"},"execution_count":null,"outputs":[]}]}